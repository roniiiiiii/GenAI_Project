# -*- coding: utf-8 -*-
"""streamlit_app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IDvSDAXcxkq4yB6TA31L0_YV-tWrlmxR
"""

#!pip install streamlit

import streamlit as st
import os
import pandas as pd
import json
import numpy as np
import base64
from io import BytesIO
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
from typing import Dict
import requests
from thematic_clusters import explore_thematic_clusters
from comparer import compare_two_artworks



# LangChain imports
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.tools import BaseTool
from pydantic import Field

# OpenAI client
from openai import OpenAI


# === DATA LOADING FUNCTIONS ===
@st.cache_data
def load_metadata():
    """Load metadata from CSV file"""
    try:
        metadata_path = "metadata.csv"
        if os.path.exists(metadata_path):
            # Specify the correct delimiter
            df = pd.read_csv(metadata_path, sep=';', on_bad_lines='warn', encoding='utf-8-sig')
            return df
        else:
            st.error(f"Metadata file not found at {metadata_path}")
            return pd.DataFrame()
    except Exception as e:
        st.error(f"Error loading metadata: {str(e)}")
        return pd.DataFrame()

@st.cache_data
def load_image_vectors():
    """Load image vectors from JSON file and normalize the structure."""
    try:
        vectors_path = "image_vectors.json"
        if os.path.exists(vectors_path):
            with open(vectors_path, 'r') as f:
                data = json.load(f)

            # Normalize the vectors dictionary
            normalized_vectors = {}
            for path, value in data.items():
                filename = os.path.basename(path)
                if isinstance(value, dict) and "embedding" in value:
                    normalized_vectors[filename] = value["embedding"]
            return normalized_vectors
        else:
            st.error(f"Image vectors file not found at {vectors_path}")
            return {}
    except Exception as e:
        st.error(f"Error loading image vectors: {str(e)}")
        return {}

def get_available_images():
    """Get list of available images in the images directory"""
    images_dir = "images"
    if os.path.exists(images_dir):
        image_files = [f for f in os.listdir(images_dir)
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        return sorted(image_files)
    else:
        st.error(f"Images directory not found at {images_dir}")
        return []

# === UTILITY FUNCTIONS ===
def encode_image_to_base64(pil_image):
    """Convert PIL image to base64 string"""
    buffered = BytesIO()
    pil_image.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode()

def load_image_and_metadata(metadata_df, image_filename=None, uploaded_file=None):
    """Load image and its metadata"""
    if uploaded_file:
        try:
            image = Image.open(uploaded_file)
            filename = uploaded_file.name
            return image, filename, None  # No metadata for uploaded files
        except Exception as e:
            st.error(f"Error loading uploaded image: {str(e)}")
            return None, None, None

    elif image_filename:
        try:
            image_path = os.path.join("images", image_filename)
            if os.path.exists(image_path):
                image = Image.open(image_path)
                meta = {}

                if not metadata_df.empty:
                    # Find metadata using filename
                    filename_col = None
                    for col in ['filename', 'image_id', 'id', 'name']:
                        if col in metadata_df.columns:
                            # Look for matches without file extension
                            base_name = image_filename.split('.')[0]
                            if any(metadata_df[col].astype(str).str.contains(base_name)):
                                filename_col = col
                                break

                    if filename_col:
                        # Find metadata row
                        base_name = image_filename.split('.')[0]
                        meta_row = metadata_df[metadata_df[filename_col].astype(str).str.contains(base_name)]
                        if not meta_row.empty:
                            meta = meta_row.iloc[0].to_dict()
                        else:
                            st.warning(f"No metadata found for {image_filename}")
                    else:
                        st.warning("Could not find a valid filename identifier column in metadata.csv.")

                return image, image_filename, meta
            else:
                st.error(f"Image not found: {image_path}")
                return None, None, None
        except Exception as e:
            st.error(f"Error loading image {image_filename}: {str(e)}")
            return None, None, None

    return None, None, None

def build_image_analysis_prompt():
    """Build prompt for image analysis"""
    return (
        "You are a feminist art expert. Carefully analyze the provided artwork. "
        "Focus on visual elements, body language, color palette, composition, symbols, and possible historical or cultural context. "
        "Provide an insightful interpretation of its mood and message."
    )

def get_ai_analysis(client, image):
    """Get AI analysis of the artwork"""
    try:
        base64_img = encode_image_to_base64(image)
        prompt = build_image_analysis_prompt()

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}}
                    ]
                }
            ],
            max_tokens=1024
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"Error getting AI analysis: {str(e)}")
        return "Error generating analysis."

def similarity_search(selected_filename, image_vectors, metadata_df):
    """Find and display similar images with metadata and nationality highlight"""
    # REMOVED: The duplicate display of selected artwork here
    if selected_filename in image_vectors:
        query_vector = np.array(image_vectors[selected_filename]).reshape(1, -1)
        results = []

        # Search for similar images
        for filename, vector in image_vectors.items():
            if filename == selected_filename:
                continue
            other_vector = np.array(vector).reshape(1, -1)
            sim = cosine_similarity(query_vector, other_vector)[0][0]
            results.append((filename, sim))

        top_results = sorted(results, key=lambda x: x[1], reverse=True)[:3]

        if top_results:
            st.markdown("### Most Similar Artworks:")
            cols = st.columns(len(top_results))

            for i, (filename, score) in enumerate(top_results):
                with cols[i]:
                    img_path = os.path.join("images", filename)
                    if os.path.exists(img_path):
                        st.image(img_path, caption=f"Similarity: {score:.3f}", use_container_width=True)

                        # Retrieve metadata
                        meta_row = metadata_df[metadata_df["id"].astype(str) + ".jpg" == filename]
                        if not meta_row.empty:
                            meta = meta_row.iloc[0]
                            artist = meta.get("artist", "Unknown")
                            title = meta.get("name", "Unknown")
                            year = meta.get("year", "Unknown")
                            nationality = meta.get("nationality", "Unknown")

                            # Display metadata with highlighted nationality
                            st.markdown(f"""
                            **Title:** {title}
                            **Artist:** {artist}
                            **Year:** {year}
                            **Nationality:** <span style='background-color:#FFFADA;padding:2px 6px;border-radius:4px;'>{nationality}</span>
                            """, unsafe_allow_html=True)
                        else:
                            st.caption("No metadata found.")
                    else:
                        st.write(f"{filename} not found.")
        else:
            st.info("No similar images found.")
    else:
        st.info("No precomputed embedding available for this artwork.")



def chat_about_artwork(client, title, artist, year, nationality, ai_analysis, additional_context=""):
    """Chat interface for artwork discussion with enhanced prompting"""

    full_context = ai_analysis or ""
    if additional_context:
        full_context += f"\n\nAdditional context from web search:\n{additional_context}"


    # Enhanced system prompt with cross-cultural visual analysis focus
    system_prompt = (
        f"You are Dr. Sarah Mitchell, a leading expert in comparative feminist art history "
        f"specializing in cross-cultural visual analysis of 1970s-1980s feminist photography. "
        f"Your research focuses on identifying visual similarities and differences across nationalities in feminist art.\n\n"
        f"ARTWORK CONTEXT:\n"
        f"- Title: {title}\n"
        f"- Artist: {artist} ({nationality})\n"
        f"- Year: {year}\n"
        f"- AI Analysis: {ai_analysis}\n\n"
        f"PRIMARY RESEARCH MISSION:\n"
        f"Investigate visual similarities between feminist artists of different nationalities during the 1970s-80s, "
        f"analyzing how universal themes of feminism were expressed through shared visual languages despite cultural differences.\n\n"
        f"ANALYTICAL APPROACH (Use Chain-of-Thought):\n"
        f"When analyzing visual elements, follow this reasoning process:\n"
        f"1. OBSERVE: Identify specific visual elements (composition, lighting, subject matter, symbols)\n"
        f"2. COMPARE: Consider how these elements appear in works by artists from other nationalities\n"
        f"3. CONTEXTUALIZE: Explain cultural/national influences vs. universal feminist themes\n"
        f"4. CONCLUDE: Assess whether similarities suggest shared feminist visual vocabulary\n\n"
        f"FEW-SHOT EXAMPLES OF CROSS-CULTURAL ANALYSIS:\n\n"
        f"Example 1: Body Representation\n"
        f"- American artist Cindy Sherman's self-portraits + German artist Katharina Sieverding's photo-performances both use fragmented/multiple identities\n"
        f"- Visual similarity: Both challenge fixed feminine identity through photographic manipulation\n"
        f"- Cultural difference: Sherman focuses on media stereotypes, Sieverding on post-war German identity politics\n\n"
        f"Example 2: Domestic Space Themes\n"
        f"- British artist Susan Hiller's installations + Japanese artist Yoko Ono's instruction pieces both critique domestic roles\n"
        f"- Visual similarity: Both use everyday objects as artistic materials\n"
        f"- Cultural difference: Hiller emphasizes archaeological documentation, Ono emphasizes conceptual participation\n\n"
        f"Example 3: Performance Documentation\n"
        f"- Yugoslav Marina Abramovic + American Carolee Schneemann both document body-based performances\n"
        f"- Visual similarity: Both use photography to capture ephemeral feminist statements about bodily autonomy\n"
        f"- Cultural difference: Abramovic emphasizes endurance/pain, Schneemann emphasizes celebration/pleasure\n\n"
        f"YOUR RESPONSE FRAMEWORK:\n"
        f"1. Direct engagement with user's question\n"
        f"2. Visual analysis of the current artwork using Chain-of-Thought process\n"
        f"3. Cross-cultural comparison with artists from other nationalities (if relevant)\n"
        f"4. Assessment of shared vs. culturally-specific visual strategies\n"
        f"5. Invitation to explore more cross-cultural connections\n\n"
        f"AVOID:\n"
        f"- Treating national identity as deterministic of artistic style\n"
        f"- Overlooking individual artistic innovation in favor of cultural generalizations\n"
        f"- Missing opportunities to draw cross-cultural visual connections\n"
        f"- Discussing only one cultural context when comparative analysis is possible\n\n"
        f"GOAL: Help users discover how feminist artists across different cultures developed both shared and distinct visual languages to express similar themes of women's liberation and identity."
    )

    # Use a unique key for session state based on the artwork title to avoid conflicts
    session_key = f"messages_{title}"
    if session_key not in st.session_state or st.session_state.get("current_artwork_title") != title:

        # Enhanced initial message focusing on cross-cultural analysis
        initial_message = (
            f"Hello! I'm excited to explore '{title}' by {artist} ({nationality}, {year}) "
            "through the lens of comparative feminist art analysis.\n\n"
            "My specialty is investigating visual similarities between feminist artists across "
            "different nationalities during the 1970s-80s. I can help you discover:\n\n"
            "🔍 Visual Analysis: Specific techniques, compositions, and symbolic elements in this work\n"
            "🌍 Cross-Cultural Connections: How this artist's approach compares to feminist photographers from other countries\n"
            "📊 Shared Visual Languages: Universal feminist themes expressed through similar artistic strategies\n"
            "🎯 Cultural Specificity: What makes this artist's national/cultural context unique\n\n"
            "Example questions you might ask:\n"
            "- How does this artist's use of lighting/composition/subject compare to feminist photographers from other countries?\n"
            f"- What visual elements here appear in feminist art globally vs. those specific to {nationality} artists?\n"
            "- Can you identify any shared feminist visual strategies across different nationalities?\n\n"
            "What aspect of this artwork's visual language would you like to explore in a cross-cultural context?"
        )

        st.session_state[session_key] = [
            {"role": "system", "content": system_prompt},
            {"role": "assistant", "content": initial_message}
        ]
        st.session_state.current_artwork_title = title

    # Display chat history
    for msg in st.session_state[session_key][1:]:  # Skip system message
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Chat input with helpful placeholder
    user_input = st.chat_input("Ask about themes, techniques, historical context, or artistic significance...")
    if user_input:
        st.session_state[session_key].append({"role": "user", "content": user_input})

        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("Analyzing artwork and context..."):
                try:
                    # Pass the correct message history to the API
                    chat_response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=st.session_state[session_key],
                        max_tokens=1024,
                        temperature=0.7  # Balanced creativity and consistency
                    )
                    reply = chat_response.choices[0].message.content
                    st.write(reply)
                    st.session_state[session_key].append({"role": "assistant", "content": reply})
                except Exception as e:
                    error_msg = f"Error generating response: {str(e)}"
                    st.error(error_msg)
                    st.session_state[session_key].append({"role": "assistant", "content": error_msg})



# === LANGCHAIN TOOLS (FOR UPLOADED IMAGE ANALYSIS) ===
class WebArtSearchTool(BaseTool):
    name: str = "web_art_search"
    description: str = "Search art on the web using SerpAPI"
    serpapi_key: str = Field(..., description="SerpAPI key for authentication")

    def _run(self, query: str) -> str:
        search_url = "https://serpapi.com/search"
        params = {
            "q": query,
            "engine": "google",
            "api_key": self.serpapi_key,
            "tbm": "isch",  # image search
        }
        try:
            response = requests.get(search_url, params=params)
            response.raise_for_status()
            data = response.json()

            images = data.get("images_results", [])
            if not images:
                return "No results found."

            # Return a richer summary including titles, links, and sources
            results_summary = "\n".join(
                [f"Title: {img.get('title', 'No Title')}, Source: {img.get('source', 'No Source')}, Link: {img.get('link', '')}" for idx, img in enumerate(images[:5])]
            )
            return results_summary
        except Exception as e:
            return f"Error during SerpAPI request: {e}"

    async def _arun(self, query: str) -> str:
        raise NotImplementedError("Async method not implemented.")


# === NEW: FUNCTION TO HANDLE UPLOADED IMAGE WORKFLOW ===
def handle_uploaded_image(client, serpapi_key, uploaded_file):
    """
    Handles the entire workflow for an uploaded image:
    1. Displays the image.
    2. Generates a search query from the image.
    3. Uses WebArtSearchTool to find information.
    4. Uses an LLM to extract metadata from search results.
    5. Performs a full AI analysis.
    6. Initiates the chat interface.
    """
    st.markdown("## Analysis of Your Uploaded Artwork")
    image = Image.open(uploaded_file)
    st.image(image, caption="Your Uploaded Artwork", use_container_width=True)

    with st.spinner("Analyzing your image to identify it..."):
        # 1. Generate a search query from the image
        search_prompt = "You are an art historian. Describe the key visual elements of this artwork for a search engine to identify it. Focus on subject matter, style, and composition. Be concise."
        base64_img = encode_image_to_base64(image)
        try:
            desc_response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": [
                    {"type": "text", "text": search_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}}
                ]}],
                max_tokens=100
            )
            search_query = desc_response.choices[0].message.content
            st.info(f"Generated Search Query: {search_query}")
        except Exception as e:
            st.error(f"Could not generate a search query from the image: {e}")
            return

    with st.spinner("Searching the web for information about this artwork..."):
        # 2. Use WebArtSearchTool to find information
        art_search_tool = WebArtSearchTool(serpapi_key=serpapi_key)
        search_results = art_search_tool._run(search_query)

    with st.spinner("Extracting metadata from search results..."):
        # 3. Use an LLM to extract metadata
        meta = {'title': 'Unknown', 'artist': 'Unknown', 'year': 'Unknown', 'nationality': 'Unknown'}
        if "Error" not in search_results:
            extraction_prompt = f"""
            Based on the following web search results for an artwork, extract the most likely Title, Artist, Year, and Nationality.
            Respond ONLY with a JSON object with the keys "title", "artist", "year", and "nationality".
            If a value cannot be found, use "Unknown".

            Search Results:
            {search_results}
            """
            try:
                meta_response = client.chat.completions.create(
                    model="gpt-4o",
                    response_format={"type": "json_object"},
                    messages=[{"role": "system", "content": "You are a helpful assistant that extracts structured data."},
                              {"role": "user", "content": extraction_prompt}],
                    max_tokens=256
                )
                extracted_meta = json.loads(meta_response.choices[0].message.content)
                meta.update(extracted_meta)

                st.markdown("### Discovered Metadata:")
                metadata_display = [f"**{key.title()}:** {value}" for key, value in meta.items() if value and value != "Unknown"]
                if metadata_display:
                    st.markdown("\n".join(metadata_display))
                else:
                    st.warning("Could not automatically identify metadata for this artwork.")

            except Exception as e:
                st.error(f"Could not extract metadata from search results: {e}")
        else:
            st.error("Web search failed. Cannot fetch metadata.")

    # 4. Perform a full AI analysis
    with st.expander("AI Artwork Analysis", expanded=True):
        with st.spinner("Performing in-depth AI analysis..."):
            ai_analysis = get_ai_analysis(client, image)
        st.markdown(f'<div class="analysis-section">{ai_analysis}</div>', unsafe_allow_html=True)

    # 5. Initiate the chat interface
    if ai_analysis:
        st.markdown("## Chat About This Artwork")
        st.markdown("Ask questions about the artwork's style, technique, historical context, or anything else you'd like to know!")
        chat_about_artwork(
            client,
            title=meta.get('title', 'Unknown'),
            artist=meta.get('artist', 'Unknown'),
            year=meta.get('year', 'Unknown'),
            nationality=meta.get('nationality', 'Unknown'),
            ai_analysis=ai_analysis
        )

def set_custom_styles():
    st.markdown(
        """
        <style>
        /* Import Google Fonts */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=Georgia:wght@400;700&display=swap');

        /* Color variables */
        :root {
            --dark-blue-text: #00008B;
            --lavender-bg: #C3BEF7;
            --main-bg: #FFEBAD;
        }

        /* === Global & Base Styles === */
        body, html, #root, .stApp, .stApp > div:last-child {
            background-color: var(--main-bg) !important;
            color: #333333 !important;
            color-scheme: light !important;
        }

        .st-emotion-cache-13k62yr {
            background: var(--main-bg) !important;
            color: #333333 !important;
        }

        header[data-testid="stHeader"] {
            background-color: var(--main-bg) !important;
            height: 0px !important;
            min-height: 0px !important;
            border-bottom: none !important;
            padding: 0 !important;
            margin: 0 !important;
        }

        .block-container {
            background-color: var(--main-bg) !important;
            padding-top: 1rem;
            padding-bottom: 1rem;
            padding-left: 3rem;
            padding-right: 3rem;
        }

        body, .stApp, .stApp *, .stMarkdown, .stText, .stLabel {
            font-family: 'Inter', sans-serif !important;
            color: #333333 !important;
        }

        h1, h2, h3, h4, h5, h6 {
            color: #333333 !important;
            font-family: 'Georgia', serif !important;
        }

        /* === ENHANCED PASSWORD VISIBILITY TOGGLE HIDING === */
        /* More comprehensive selectors to hide password toggle buttons */
        button[aria-label="Show password text"],
        button[aria-label="Hide password text"],
        button[title="Show password text"],
        button[title="Hide password text"],
        [data-baseweb="base-input"] button,
        [data-baseweb="base-input"] button[type="button"],
        div[data-baseweb="base-input"] button[type="button"],
        .st-co.st-c9.st-ca.st-c7.st-c8.st-cp.st-cq.st-cr.st-cb.st-c1,
        button.st-b4.st-co.st-c9.st-ca.st-c7.st-c8.st-cp.st-cq.st-cr.st-cb.st-c1,
        [data-testid="stTextInput-RootElement"] button,
        [data-testid="stTextInput-RootElement"] button[type="button"],
        input[type="password"] + button,
        input[type="password"] ~ button {
            display: none !important;
            visibility: hidden !important;
            width: 0 !important;
            height: 0 !important;
            opacity: 0 !important;
            pointer-events: none !important;
            position: absolute !important;
            left: -9999px !important;
        }

        /* Hide the SVG icon specifically */
        button[aria-label="Show password text"] svg,
        button[aria-label="Hide password text"] svg,
        button[title="Show password text"] svg,
        button[title="Hide password text"] svg,
        [data-baseweb="base-input"] button svg,
        [data-testid="stTextInput-RootElement"] button svg,
        svg[data-baseweb="icon"][title="Show password text"],
        svg[data-baseweb="icon"][title="Hide password text"] {
            display: none !important;
            visibility: hidden !important;
        }

        /* Force hide any button inside password input containers */
        [data-testid="stTextInput-RootElement"]:has(input[type="password"]) button,
        div:has(input[type="password"]) button[type="button"] {
            display: none !important;
            visibility: hidden !important;
        }

        /* Fix for dark backgrounds on various elements */
        .st-bx, .st-ea, .st-bd, .st-bc, .st-ax, .st-aw, .st-ay, .st-av, .st-bf, .st-bg {
            background-color: transparent !important;
        }

        /* --- SIDEBAR STYLING --- */
        [data-testid="stSidebar"] {
            background-color: var(--lavender-bg) !important;
        }

        /* Target all text elements within the sidebar */
        [data-testid="stSidebar"] * {
            color: var(--dark-blue-text) !important;
        }

        /* === SIDEBAR INPUT FIELDS === */
        /* Target the root element of sidebar text inputs */
        [data-testid="stSidebar"] [data-testid="stTextInput-RootElement"],
        [data-testid="stSidebar"] [data-baseweb="input"] {
            background-color: #FFFFFF !important;
            border: 1px solid var(--dark-blue-text) !important;
            border-radius: 8px !important;
            padding: 0.25rem !important;
        }

        /* Target the actual input element */
        [data-testid="stSidebar"] [data-testid="stTextInput-RootElement"] input,
        [data-testid="stSidebar"] [data-baseweb="input"] input {
            background-color: #FFFFFF !important;
            color: var(--dark-blue-text) !important;
        }

        /* === SIDEBAR BUTTONS: WHITE BG WITH BLUE TEXT === */
        [data-testid="stSidebar"] .stButton > button,
        [data-testid="stSidebar"] button,
        section[data-testid="stSidebar"] .stButton > button,
        section[data-testid="stSidebar"] button,
        [data-testid="stSidebar"] [kind="primary"],
        [data-testid="stSidebar"] [kind="secondary"],
        [data-testid="stSidebar"] [data-baseweb="button"] {
            background-color: #FFFFFF !important;
            color: var(--dark-blue-text) !important;
            border: 1px solid var(--dark-blue-text) !important;
            border-radius: 8px !important;
            font-weight: 600 !important;
            padding: 0.5em 1em !important;
            box-shadow: none !important;
        }

        /* Ensure sidebar input text is also dark blue */
        [data-testid="stSidebar"] input,
        [data-testid="stSidebar"] .stTextInput input {
            color: var(--dark-blue-text) !important;
            background-color: #FFFFFF !important;
        }

        /* === SIDEBAR SELECTBOX: WHITE BACKGROUND === */
        [data-testid="stSidebar"] .stSelectbox [data-baseweb="select"],
        [data-testid="stSidebar"] .stSelectbox [data-baseweb="select"] > div,
        [data-testid="stSidebar"] .stSelectbox [data-baseweb="popover"] {
            background-color: #FFFFFF !important;
            color: var(--dark-blue-text) !important;
            border: 1px solid var(--dark-blue-text) !important;
            border-radius: 8px !important;
        }

        [data-testid="stSidebar"] .stSelectbox svg {
            color: var(--dark-blue-text) !important;
        }

        /* === MAIN PAGE SELECTBOX: LAVENDER BACKGROUND === */
        .stSelectbox [data-baseweb="select"],
        .stSelectbox [data-baseweb="select"] > div,
        .stSelectbox [data-baseweb="popover"] {
            background-color: var(--lavender-bg) !important;
            color: var(--dark-blue-text) !important;
            border: 1px solid var(--dark-blue-text) !important;
            border-radius: 8px !important;
        }

        /* === ENHANCED DROPDOWN OPTIONS STYLING === */
        /* Target dropdown container */
        .stSelectbox [data-baseweb="popover"],
        .stSelectbox [data-baseweb="popover"] > div,
        .stSelectbox [data-baseweb="popover"] ul {
            background-color: var(--lavender-bg) !important;
            border: 1px solid var(--dark-blue-text) !important;
            border-radius: 8px !important;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1) !important;
        }

        /* Target individual dropdown options */
        .stSelectbox [data-baseweb="popover"] li,
        .stSelectbox li[role="option"],
        li.st-emotion-cache-1ppef92,
        li.st-emotion-cache-doy61h,
        .stSelectbox [id*="val-"] {
            background-color: var(--lavender-bg) !important;
            color: var(--dark-blue-text) !important;
            border: none !important;
            padding: 8px 12px !important;
        }

        /* Hover state for dropdown options */
        .stSelectbox [data-baseweb="popover"] li:hover,
        .stSelectbox li[role="option"]:hover,
        li.st-emotion-cache-1ppef92:hover,
        li.st-emotion-cache-doy61h:hover,
        .stSelectbox [id*="val-"]:hover {
            background-color: #b0a9f0 !important;
            color: var(--dark-blue-text) !important;
        }

        /* Selected state for dropdown options */
        .stSelectbox [data-baseweb="popover"] li[aria-selected="true"],
        .stSelectbox li[role="option"][aria-selected="true"],
        li.st-emotion-cache-1ppef92[aria-selected="true"] {
            background-color: #a89ef5 !important;
            color: var(--dark-blue-text) !important;
            font-weight: 600 !important;
        }

        /* Target the text content inside dropdown options */
        .stSelectbox [data-baseweb="popover"] li div,
        .stSelectbox [data-baseweb="popover"] li span,
        .st-emotion-cache-sy3zga,
        .st-emotion-cache-87mhkc {
            color: var(--dark-blue-text) !important;
            background-color: transparent !important;
        }

        .stSelectbox svg {
            color: var(--dark-blue-text) !important;
        }

        /* --- FILE UPLOADER STYLING - FULL LAVENDER BACKGROUND --- */
        [data-testid="stFileUploaderDropzone"],
        .stFileUploader > div,
        .stFileUploader [data-testid="stFileUploaderDropzone"],
        div[data-testid="stFileUploaderDropzone"] {
            border: 2px dashed var(--dark-blue-text) !important;
            background-color: var(--lavender-bg) !important;
            padding: 2rem !important;
            border-radius: 12px !important;
            min-height: 120px !important;
        }

        /* File uploader inner content */
        [data-testid="stFileUploaderDropzone"] > div,
        .stFileUploader > div > div > div {
            background-color: var(--lavender-bg) !important;
        }

        /* "Browse files" button inside the uploader */
        [data-testid="stFileUploaderDropzone"] button,
        .stFileUploader button,
        [data-testid="stFileUploaderDropzone"] .stButton > button {
            background-color: #FFFFFF !important;
            color: var(--dark-blue-text) !important;
            border: 1px solid var(--dark-blue-text) !important;
            border-radius: 8px !important;
            font-weight: 600 !important;
        }

        /* File uploader text styling */
        [data-testid="stFileUploaderDropzone"] p,
        [data-testid="stFileUploaderDropzone"] span,
        [data-testid="stFileUploaderDropzone"] div,
        [data-testid="stFileUploaderDropzone"] label,
        .stFileUploader p,
        .stFileUploader span,
        .stFileUploader div {
            color: var(--dark-blue-text) !important;
            font-weight: 500 !important;
        }

        /* === MAIN PAGE BUTTONS: LAVENDER BG WITH BLUE TEXT === */
        .stButton > button:not([data-testid="stSidebar"] .stButton > button),
        button:not([data-testid="stSidebar"] button),
        [data-testid="column"] .stButton > button,
        [data-testid="column"] button,
        .element-container .stButton > button,
        .element-container button {
            background-color: var(--lavender-bg) !important;
            color: var(--dark-blue-text) !important;
            border: 1px solid var(--dark-blue-text) !important;
            border-radius: 8px !important;
            font-weight: 600 !important;
            padding: 0.5em 1em !important;
            box-shadow: none !important;
        }

        /* === TEXT INPUTS === */
        [data-testid="stTextInput"] input {
            background-color: #FFFFFF !important;
            color: var(--dark-blue-text) !important;
            border: 1px solid var(--lavender-bg) !important;
            border-radius: 8px !important;
            box-shadow: none !important;
        }

        /* === EXPANDERS === */
        [data-testid="stExpander"] details summary {
            background-color: var(--lavender-bg) !important;
            color: var(--dark-blue-text) !important;
            font-weight: 600 !important;
            padding: 10px !important;
            border-radius: 8px !important;
            border: 1px solid var(--dark-blue-text) !important;
        }

        /* === IMAGES === */
        img {
            max-height: 500px;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }

        /* === ALERTS === */
        .stAlert {
            background-color: #FFFBEC !important;
            border: 1px solid #EADCA6 !important;
            border-radius: 8px !important;
        }

        /* === ANALYSIS SECTION === */
        .analysis-section {
            background-color: #FFFBEC;
            border: 2px solid #EADCA6;
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            box-shadow: none !important;
        }

        /* === CHAT INPUT === */
        [data-testid="stChatInput"] {
            background-color: var(--main-bg) !important;
            border: 2px solid var(--lavender-bg) !important;
            border-radius: 8px !important;
            box-shadow: none !important;
        }

        /* === OVERRIDE COMPARER.PY STYLING === */
        [data-testid="stSidebar"] .stButton > button {
            background-color: #FFFFFF !important;
            color: var(--dark-blue-text) !important;
        }

        .main .stButton > button,
        .block-container .stButton > button {
            background-color: var(--lavender-bg) !important;
            color: var(--dark-blue-text) !important;
        }

        [data-testid="stFileUploaderDropzone"] {
            background-color: var(--lavender-bg) !important;
            border: 2px dashed var(--dark-blue-text) !important;
        }

        [data-testid="stFileUploaderDropzone"] button {
            background-color: #FFFFFF !important;
            color: var(--dark-blue-text) !important;
        }
                /* ... (previous styles remain) ... */

        /* NEW: Style for Generate AI Analysis button */
        .generate-analysis-btn {
            background-color: #6A5ACD !important;
            color: white !important;
            border: none !important;
            border-radius: 8px !important;
            padding: 8px 16px !important;
            font-weight: 600 !important;
            margin-top: 10px;
            transition: background-color 0.3s;
        }

        .generate-analysis-btn:hover {
            background-color: #5D4EC2 !important;
        }

        /* Collapsible filter section styling */
        .collapsible-filter {
            background-color: #F0F2F6;
            border-radius: 8px;
            padding: 10px;
            margin-bottom: 15px;
        }

        .collapsible-header {
            display: flex;
            align-items: center;
            cursor: pointer;
            font-weight: 600;
        }

        .collapsible-content {
            padding: 10px 0;
        }

        .arrow {
            margin-right: 8px;
            transition: transform 0.3s;
        }

        .arrow.down {
            transform: rotate(90deg);
        }
        </style>
        """,
        unsafe_allow_html=True
    )


def explore_one_artwork(client, metadata_df, image_vectors, available_images, serpapi_key):
    set_custom_styles()
    st.title("Explore One Artwork")
    st.info("Choose an artwork and discover visually similar ones.\n"
        "Are there similarities between artists of different nationalities?")

    if 'nationality' in metadata_df.columns:
        nationalities = sorted(metadata_df['nationality'].dropna().astype(str).unique())
    else:
        nationalities = []

    # --- Identify the correct filename column ---
    filename_col = None
    if not metadata_df.empty:
        for col in ['filename', 'id', 'image_id', 'name']:
            if col in metadata_df.columns:
                filename_col = col
                break

    # --- COLLAPSIBLE FILTER SECTION ---


    # Create unique, sorted lists for filters
    artists = ["All"] + sorted(metadata_df['artist'].dropna().astype(str).unique())
    years = ["All"] + sorted(metadata_df['year'].dropna().astype(str).unique())
    nationalities = ["All"] + sorted(metadata_df['nationality'].dropna().astype(str).unique())

    col1, col2, col3 = st.columns(3)
    with col1:
        selected_artist = st.selectbox("Filter by Artist", artists, index=0)
    with col2:
        selected_year = st.selectbox("Filter by Year", years, index=0)
    with col3:
        selected_nationality = st.selectbox("Filter by Nationality", nationalities, index=0)

    st.markdown("</div></div>", unsafe_allow_html=True)

    # JavaScript to handle collapsible section
    st.markdown(
        """
        <script>
        document.querySelector('.collapsible-header').addEventListener('click', function() {
            const content = this.nextElementSibling;
            if (content.style.display === 'none') {
                content.style.display = 'block';
            } else {
                content.style.display = 'none';
            }
        });
        </script>
        """,
        unsafe_allow_html=True
    )

    # Filter metadata
    filtered_df = metadata_df.copy()
    if selected_artist != "All":
        filtered_df = filtered_df[filtered_df['artist'] == selected_artist]
    if selected_year != "All":
        filtered_df = filtered_df[filtered_df['year'].astype(str) == selected_year]
    if selected_nationality != "All":
        filtered_df = filtered_df[filtered_df['nationality'] == selected_nationality]

    # Get filtered image filenames
    filtered_images = list(filtered_df[filename_col]) if filename_col else available_images
    filtered_images = [f if str(f).endswith('.jpg') else str(f) + '.jpg' for f in filtered_images]

    # --- SELECTION SECTION ---
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### Choose an artwork")
        if not filtered_images:
            st.warning("No artworks match the current filter criteria.")
            selected_filename = None
        else:
            # Create a mapping from a display name (like title) to the actual filename
            if not filtered_df.empty and 'title' in filtered_df.columns:
                # Create a list of "Title (filename)" for the dropdown
                display_options = {f"{row['title']} ({row[filename_col]})": row[filename_col]
                                  for index, row in filtered_df.iterrows()}
                display_name = st.selectbox("Artwork", display_options.keys(), label_visibility="collapsed")
                selected_filename = display_options[display_name] if display_name else None
            else:
                selected_filename = st.selectbox("Artwork", filtered_images, label_visibility="collapsed")

    with col2:
        st.markdown("#### Or Upload Your Own")
        uploaded_file = st.file_uploader("Upload an image for analysis", type=["jpg", "jpeg", "png"],
                                         label_visibility="collapsed")

    st.markdown("---")

    # --- DISPLAY SECTION ---
    if uploaded_file:
        if serpapi_key:
            handle_uploaded_image(client, serpapi_key, uploaded_file)
        else:
            st.error("A SerpAPI key is required to analyze uploaded images. Please add it in the sidebar.")

    elif selected_filename:
        image, filename, meta = load_image_and_metadata(
            metadata_df,
            image_filename=selected_filename
        )

        web_context = ""
        if serpapi_key and meta:
            with st.spinner("Searching the web for this artwork..."):
                # Use WebArtSearchTool directly instead of handle_uploaded_image
                art_search_tool = WebArtSearchTool(serpapi_key=serpapi_key)
                query = f"{meta.get('title', '')} by {meta.get('artist', '')}"
                if query.strip():
                    web_context = art_search_tool._run(query)

        if image:
            # Display selected artwork only once at the top
            st.markdown("## Selected Artwork")
            col_orig, col_meta = st.columns([2, 3])

            with col_orig:
                st.image(image, caption=meta.get('title', filename), use_container_width=True)

            with col_meta:
                if meta:
                    display_key = filename_col if filename_col else 'filename'
                    metadata_display = [
                        f"**{key.title()}:** {value}"
                        for key, value in meta.items()
                        if pd.notna(value) and value != "" and key != display_key
                    ]
                    if metadata_display:
                        st.markdown("\n".join(metadata_display))
                    else:
                        st.info("No metadata available for this artwork.")



            # In explore_one_artwork function:
            st.markdown('<div class="generate-analysis-btn-container">', unsafe_allow_html=True)
            if st.button("Generate AI Analysis",
                          key="ai_analysis_btn",
                          help="Get feminist art analysis of this artwork",
                          use_container_width=True,
                          type="primary"):
              with st.expander("AI Artwork Analysis", expanded=True):
                  with st.spinner("Analyzing artwork..."):
                      ai_analysis = get_ai_analysis(client, image)
                  st.markdown(f'<div class="analysis-section">{ai_analysis}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

            # Similar artworks section
            st.markdown("## Visually Similar Artworks")
            similarity_search(filename, image_vectors, metadata_df)

            # Chat section
            st.markdown("## Chat About This Artwork")
            st.markdown("Ask questions about the artwork's style, technique, historical context, or anything else!")
            chat_about_artwork(
                client,
                meta.get('title', meta.get('name', 'Unknown')),
                meta.get('artist', 'Unknown'),
                meta.get('year', 'Unknown'),
                meta.get('nationality', 'Unknown'),
                ai_analysis if 'ai_analysis' in locals() else "",
                additional_context=web_context
            )
        else:
            st.error("Error loading the selected image.")

# ... (rest of the code remains the same)


def compare_two_artworks(client, metadata_df, available_images):
    set_custom_styles()
    st.title("Compare Two Artworks")

    if not available_images:
        st.error("No images found in the images directory")
        return

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("### First Artwork")
        selected_filename1 = st.selectbox("Select first artwork", available_images, key="art1")

    with col2:
        st.markdown("### Second Artwork")
        selected_filename2 = st.selectbox("Select second artwork", available_images, key="art2")

    if selected_filename1 and selected_filename2 and selected_filename1 != selected_filename2:
        image1, _, meta1 = load_image_and_metadata(metadata_df, image_filename=selected_filename1)
        image2, _, meta2 = load_image_and_metadata(metadata_df, image_filename=selected_filename2)

        if image1 and image2:
            st.markdown("## Artworks Comparison")
            col1, col2 = st.columns(2)

            with col1:
                st.image(image1, caption=meta1.get('title', meta1.get('name', 'Artwork 1')) if meta1 else 'Artwork 1', use_container_width=True)
                if meta1:
                    metadata_display = []
                    for key, value in meta1.items():
                        if pd.notna(value) and value != "":
                            metadata_display.append(f"**{key.title()}:** {value}")
                    if metadata_display:
                        st.markdown("\n".join(metadata_display))

            with col2:
                st.image(image2, caption=meta2.get('title', meta2.get('name', 'Artwork 2')) if meta2 else 'Artwork 2', use_container_width=True)
                if meta2:
                    metadata_display = []
                    for key, value in meta2.items():
                        if pd.notna(value) and value != "":
                            metadata_display.append(f"**{key.title()}:** {value}")
                    if metadata_display:
                        st.markdown("\n".join(metadata_display))

            st.markdown("## AI Analysis")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("### First Artwork Analysis")
                with st.spinner("Analyzing first artwork..."):
                    analysis1 = get_ai_analysis(client, image1)
                st.markdown(f'<div class="analysis-section">{analysis1}</div>', unsafe_allow_html=True)

            with col2:
                st.markdown("### Second Artwork Analysis")
                with st.spinner("Analyzing second artwork..."):
                    analysis2 = get_ai_analysis(client, image2)
                st.markdown(f'<div class="analysis-section">{analysis2}</div>', unsafe_allow_html=True)

            st.markdown("## Comparative Analysis")
            with st.spinner("Generating comparative analysis..."):
                try:
                    comparative_prompt = f"""
                    You are a feminist art historian. Compare the following two artworks based on provided analyses.

                    Artwork 1: {meta1.get('title', meta1.get('name', 'Unknown')) if meta1 else 'Unknown'} by {meta1.get('artist', 'Unknown') if meta1 else 'Unknown'} ({meta1.get('year', 'Unknown') if meta1 else 'Unknown'})
                    Analysis: {analysis1}

                    Artwork 2: {meta2.get('title', meta2.get('name', 'Unknown')) if meta2 else 'Unknown'} by {meta2.get('artist', 'Unknown') if meta2 else 'Unknown'} ({meta2.get('year', 'Unknown') if meta2 else 'Unknown'})
                    Analysis: {analysis2}

                    Focus on:
                    - Visual and thematic similarities
                    - Differences in artistic style and technique
                    - Cultural and historical significance
                    - Feminist perspectives or challenges represented

                    Provide a thoughtful and structured comparison.
                    """

                    comparison_response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[{"role": "user", "content": comparative_prompt}],
                        max_tokens=1024
                    )
                    comparison = comparison_response.choices[0].message.content

                    st.markdown(f'<div class="analysis-section">{comparison}</div>', unsafe_allow_html=True)
                except Exception as e:
                    st.error(f"Error generating comparative analysis: {str(e)}")
        else:
            st.error("Error loading one or both images.")
    else:
        st.info("Please select two different artworks to compare.")


# === MAIN APPLICATION ===
def main():
    set_custom_styles()

    # Load data
    metadata_df = load_metadata()
    image_vectors = load_image_vectors()
    available_images = get_available_images()

    # Sidebar for API keys and navigation
    with st.sidebar:
        st.title("Art Analysis Suite")

        # API key inputs
        st.markdown("### API Configuration")
        openai_api_key = st.text_input("OpenAI API Key:", type="password")
        serpapi_key = st.text_input("SerpAPI Key:", type="password", help="Required for analyzing uploaded images.")

        st.markdown("### Navigation")
        page = st.selectbox(
            "Choose a feature:",
            ["Explore One Artwork", "Compare Two Artworks", "Thematic Clusters"] # Removed "Advanced RAG Agent"
        )
        st.markdown("---")
        # Data status can be moved here or kept as is
        st.markdown("### Data Status")
        st.info(f"Metadata: {len(metadata_df)} records")
        st.info(f"Vectors: {len(image_vectors)} images")
        st.info(f"Images: {len(available_images)} files")


    # Main content area
    if openai_api_key:
        client = OpenAI(api_key=openai_api_key)

        if page == "Explore One Artwork":
            explore_one_artwork(client, metadata_df, image_vectors, available_images, serpapi_key)
        elif page == "Compare Two Artworks":
            compare_two_artworks(client, metadata_df, available_images)
        elif page == "Thematic Clusters":
            explore_thematic_clusters(metadata_df, image_vectors, openai_api_key)

    else:
        st.markdown("# Welcome to the Art Analysis Suite")
        st.markdown("""
        This application offers two powerful features for art analysis:

        ### Explore One Artwork
        - **Filter & Select:** Browse the collection by artist, year, or nationality.
        - **Upload & Analyze:** Upload your own art image. The app will search the web to identify it and provide a detailed analysis.
        - **AI Analysis:** Get AI-powered analysis with feminist art perspectives for any artwork.
        - **Visual Similarity:** For collection items, find visually similar artworks.
        - **Interactive Chat:** Ask detailed questions about any artwork, whether from the collection or one you uploaded.

        ### Compare Two Artworks
        - **Side-by-Side:** A direct comparison of any two artworks from the collection.
        - **Dual Analysis:** Get individual AI analysis for each piece.
        - **Comparative Report:** Receive a comprehensive report comparing and contrasting the two artworks from a feminist art history perspective.

        **Please enter your OpenAI API key in the sidebar to get started!**
        A SerpAPI key is also required if you wish to use the image upload feature.
        """)
        if not openai_api_key:
            st.warning("Please enter your OpenAI API key in the sidebar to use the application.")

        if not available_images or metadata_df.empty or not image_vectors:
             st.error("Data files (images, metadata.csv, image_vectors.json) not found or empty. Please ensure they are in the correct location.")

if __name__ == "__main__":
    main()



